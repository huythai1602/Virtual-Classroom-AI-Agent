# Há»‡ thá»‘ng Agentic RAG - Trá»£ giáº£ng ToÃ¡n lá»›p 4

Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) sá»­ dá»¥ng LangGraph, OpenAI LLM, vÃ  ChromaDB Ä‘á»ƒ trá»£ giáº£ng ToÃ¡n lá»›p 4.

---

## TÃ­nh nÄƒng chÃ­nh

- **Chat thÃ´ng minh**: Tráº£ lá»i cÃ¢u há»i vá»›i 2 cháº¿ Ä‘á»™ (ngáº¯n gá»n/chi tiáº¿t)
- **SÆ¡ Ä‘á»“ tÆ° duy**: Táº¡o mindmap JSON cho React Flow
- **PhÃ¢n tÃ­ch buá»•i há»c**: ÄÃ¡nh giÃ¡ káº¿t quáº£ há»c táº­p + Level assessment
- **Level API**: Backend services cÃ³ thá»ƒ query level cá»§a user qua GET endpoint
- **Session management**: Quáº£n lÃ½ há»™i thoáº¡i theo thread_id
- **Streaming response**: Response real-time giá»‘ng ChatGPT
- **Tá»‘i Æ°u token**: Giáº£m 70-83% chi phÃ­ vá»›i GPT-3.5/GPT-4 hybrid

---

## CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies

```powershell
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh API key

Táº¡o file `.env` tá»« template:

```powershell
copy .env.example .env
```

ThÃªm OpenAI API key vÃ o `.env`:

```env
OPENAI_API_KEY=sk-your-api-key-here
```

### 3. Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t file transcript bÃ i giáº£ng (`.txt` hoáº·c `.pdf`) vÃ o `data/transcripts/`

### 4. Build Vector Store

```powershell
python vector_store/build_chroma.py
```

---

## Cháº¡y server

```powershell
python app.py
```

Server cháº¡y táº¡i: `http://localhost:8000`

---

## API Endpoints

### 1. Chat (Regular)
```http
POST /chat
Content-Type: application/json

{
  "thread_id": "student_001",
  "user_message": "PhÃ¢n sá»‘ lÃ  gÃ¬?",
  "lesson_id": "bai_2_phan_so"
}
```

### 2. Chat (Streaming)
```http
POST /chat/stream
Content-Type: application/json

{
  "thread_id": "student_001",
  "user_message": "PhÃ¢n sá»‘ lÃ  gÃ¬?",
  "lesson_id": "bai_2_phan_so"
}
```

Response: Server-Sent Events
```
data: {"chunk": "á»’, cÃ¢u há»i hay!", "done": false}
data: {"chunk": "", "done": true}
```

### 3. Táº¡o Mindmap
```http
POST /mindmap
Content-Type: application/json

{
  "lesson_id": "bai_2_phan_so",
  "topic": "phÃ¢n sá»‘"
}
```

### 4. PhÃ¢n tÃ­ch buá»•i há»c
```http
POST /analyzer
Content-Type: application/json

{
  "thread_id": "student_001",
  "lesson_id": "bai_2_phan_so",
  "topic": "phÃ¢n sá»‘"
}
```

Response:
```json
{
  "analysis": "PhÃ¢n tÃ­ch chi tiáº¿t...",
  "thread_id": "student_001",
  "level": "Intermediate",
  "level_reason": "Em Ä‘Ã£ há»i 5 cÃ¢u há»i, thá»ƒ hiá»‡n sá»± chá»§ Ä‘á»™ng há»c há»i"
}
```

### 5. Láº¥y Level cá»§a User (Cho Backend Services)
```http
GET /user/{thread_id}/level
```

Response:
```json
{
  "thread_id": "student_001",
  "level": "Intermediate",
  "level_reason": "Em Ä‘Ã£ há»i 5 cÃ¢u há»i, thá»ƒ hiá»‡n sá»± chá»§ Ä‘á»™ng há»c há»i",
  "messages_count": 10,
  "has_conversation": true
}
```

**LÆ°u Ã½:** 
- Level chá»‰ available sau khi gá»i `/analyzer`
- Náº¿u chÆ°a gá»i analyzer, level máº·c Ä‘á»‹nh lÃ  "Beginner"
- Levels: `Beginner`, `Intermediate`, `Advanced`

### 6. Quáº£n lÃ½ Session
```http
GET /session/{thread_id}
DELETE /session/{thread_id}
```

### 7. Danh sÃ¡ch bÃ i há»c
```http
GET /lessons
```

---

## Cáº¥u trÃºc dá»± Ã¡n

```
langgraph_agent/
â”œâ”€â”€ app.py                      # FastAPI backend
â”œâ”€â”€ requirements.txt            
â”œâ”€â”€ .env                        # API keys (tá»± táº¡o)
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ graph.py               # LangGraph workflow
â”‚   â”œâ”€â”€ prompts.py             # Prompt templates
â”‚   â”œâ”€â”€ memory.py              # Session management
â”‚   â””â”€â”€ tools/                 # Tools (retriever, answer, explain, mindmap, analyzer, summarizer)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transcripts/           # Transcript files (.txt, .pdf)
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ build_chroma.py        # Build vector DB
â””â”€â”€ chroma_db/                 # Vector store (auto-generated)
```

---

## Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t

- **LangGraph**: Stateful workflow vá»›i nodes/edges
- **GPT-4**: Giáº£i thÃ­ch chi tiáº¿t, mindmap
- **GPT-3.5-turbo**: Tráº£ lá»i ngáº¯n, phÃ¢n tÃ­ch (tá»‘i Æ°u chi phÃ­)
- **ChromaDB**: Vector database
- **FastAPI**: REST API + Streaming
- **MemorySaver**: Conversation history

---

## LÆ°u Ã½

- Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« transcript
- Giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n, phÃ¹ há»£p há»c sinh lá»›p 4
- Temperature = 0 cho tÃ­nh nháº¥t quÃ¡n
- Má»—i `thread_id` = 1 cuá»™c há»™i thoáº¡i riÃªng

---

## ğŸ³ Triá»ƒn khai vá»›i Docker

### YÃªu cáº§u
- Docker Desktop (Windows/Mac) hoáº·c Docker Engine (Linux)
- Docker Compose v3.8+

### CÃ¡ch 1: Sá»­ dá»¥ng Docker Compose (Khuyáº¿n nghá»‹)

#### BÆ°á»›c 1: Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng
```powershell
# Copy file .env.example thÃ nh .env
copy .env.example .env

# Má»Ÿ .env vÃ  Ä‘iá»n OPENAI_API_KEY
notepad .env
```

#### BÆ°á»›c 2: Build vÃ  cháº¡y
```powershell
# Build vÃ  cháº¡y táº¥t cáº£ services
docker-compose up --build

# Hoáº·c cháº¡y á»Ÿ cháº¿ Ä‘á»™ background (detached)
docker-compose up -d --build
```

#### BÆ°á»›c 3: Kiá»ƒm tra
- API: http://localhost:8000
- Health check: http://localhost:8000/
- API docs: http://localhost:8000/docs

#### BÆ°á»›c 4 (TÃ¹y chá»n): Expose ra public URL vá»›i Ngrok
```powershell
# 1. Láº¥y Ngrok authtoken tá»«: https://dashboard.ngrok.com/get-started/your-authtoken
# 2. ThÃªm vÃ o .env:
#    NGROK_AUTHTOKEN=your_token_here

# 3. Restart docker-compose
docker-compose down
docker-compose up -d

# 4. Kiá»ƒm tra Ngrok URL
# Má»Ÿ browser: http://localhost:4040
# Hoáº·c xem logs:
docker-compose logs ngrok
```

**Láº¥y Public URL:**
- Má»Ÿ http://localhost:4040 Ä‘á»ƒ xem Ngrok dashboard
- Copy URL dáº¡ng: `https://xxxx-xx-xx-xxx-xxx.ngrok-free.app`
- DÃ¹ng URL nÃ y Ä‘á»ƒ test tá»« báº¥t ká»³ Ä‘Ã¢u (mobile, Postman, webhook...)

#### Dá»«ng services
```powershell
# Dá»«ng vÃ  xÃ³a containers
docker-compose down

# Dá»«ng vÃ  xÃ³a cáº£ volumes (data/chroma_db)
docker-compose down -v
```

### CÃ¡ch 2: Sá»­ dá»¥ng Docker thuáº§n

#### Build image
```powershell
docker build -t langgraph-agent:latest .
```

#### Cháº¡y container
```powershell
docker run -d `
  --name langgraph-agent `
  -p 8000:8000 `
  -e OPENAI_API_KEY=sk-your-api-key-here `
  -v ${PWD}/data:/app/data `
  -v ${PWD}/chroma_db:/app/chroma_db `
  langgraph-agent:latest
```

#### Xem logs
```powershell
docker logs -f langgraph-agent
```

#### Dá»«ng vÃ  xÃ³a container
```powershell
docker stop langgraph-agent
docker rm langgraph-agent
```

### CÃ¡c lá»‡nh Docker há»¯u Ã­ch

```powershell
# Xem containers Ä‘ang cháº¡y
docker ps

# Xem logs
docker-compose logs -f web

# Cháº¡y lá»‡nh trong container
docker-compose exec web python vector_store/build_chroma.py

# Rebuild khi cÃ³ thay Ä‘á»•i code
docker-compose up --build

# Xem resource usage
docker stats
```

### Cáº¥u trÃºc Volumes

Docker Compose tá»± Ä‘á»™ng mount cÃ¡c thÆ° má»¥c sau:
- `./data` â†’ `/app/data` (Transcripts)
- `./chroma_db` â†’ `/app/chroma_db` (Vector database)
- `.` â†’ `/app` (Source code - chá»‰ cho development)

### Troubleshooting

#### Lá»—i: "Cannot connect to the Docker daemon"
```powershell
# Äáº£m báº£o Docker Desktop Ä‘ang cháº¡y
# Khá»Ÿi Ä‘á»™ng Docker Desktop vÃ  thá»­ láº¡i
```

#### Lá»—i: "Port 8000 is already allocated"
```powershell
# Dá»«ng process Ä‘ang dÃ¹ng port 8000
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Hoáº·c thay Ä‘á»•i port trong docker-compose.yml
ports:
  - "8001:8000"  # Thay 8000 thÃ nh 8001
```

#### Lá»—i: "OPENAI_API_KEY not set"
```powershell
# Kiá»ƒm tra file .env cÃ³ tá»“n táº¡i khÃ´ng
dir .env

# Äáº£m báº£o file .env cÃ³ ná»™i dung:
# OPENAI_API_KEY=sk-...
```

#### Rebuild tá»« Ä‘áº§u (clean build)
```powershell
docker-compose down -v
docker-compose build --no-cache
docker-compose up
```

### Production Deployment

Äá»ƒ deploy production, khuyáº¿n nghá»‹:

1. **Bá» mount source code** trong `docker-compose.yml`:
```yaml
volumes:
  # - .:/app  # Comment dÃ²ng nÃ y
  - ./data:/app/data
  - ./chroma_db:/app/chroma_db
```

2. **Sá»­ dá»¥ng .env file riÃªng cho production**:
```powershell
docker-compose --env-file .env.production up -d
```

3. **ThÃªm reverse proxy** (Nginx/Traefik) cho SSL/TLS

4. **Enable monitoring** (Prometheus/Grafana)

5. **Setup log aggregation** (ELK stack)

### Docker Image Size Optimization

Image hiá»‡n táº¡i sá»­ dá»¥ng `python:3.9-slim` (khoáº£ng ~450MB sau build).

Äá»ƒ giáº£m size hÆ¡n ná»¯a:
- Sá»­ dá»¥ng multi-stage build
- DÃ¹ng Alpine Linux base image
- Loáº¡i bá» build dependencies sau khi cÃ i Ä‘áº·t

---

## ğŸ¯ Cáº£i tiáº¿n Äá»™ ChÃ­nh XÃ¡c (v2.0)

### CÃ¡c ká»¹ thuáº­t Ä‘Ã£ Ã¡p dá»¥ng:

#### 1. Chain-of-Thought Prompting
- YÃªu cáº§u LLM giáº£i thÃ­ch tá»«ng bÆ°á»›c tÆ° duy
- TÄƒng Ä‘á»™ chÃ­nh xÃ¡c lÃªn ~30% cho bÃ i toÃ¡n logic
- Ãp dá»¥ng trong cháº¿ Ä‘á»™ "Deep" (giáº£i thÃ­ch chi tiáº¿t)

#### 2. Few-Shot Examples
- Cung cáº¥p 2-3 vÃ­ dá»¥ máº«u trong prompt
- GiÃºp LLM hiá»ƒu rÃµ format vÃ  style cÃ¢u tráº£ lá»i mong Ä‘á»£i
- Giáº£m thiá»ƒu cÃ¢u tráº£ lá»i sai format

#### 3. Temperature = 0
- Loáº¡i bá» tÃ­nh ngáº«u nhiÃªn trong response
- Äáº£m báº£o cÃ¢u tráº£ lá»i nháº¥t quÃ¡n, cÃ³ thá»ƒ reproduce
- Ãp dá»¥ng cho Táº¤T Cáº¢ LLM calls

#### 4. Self-Critique Mechanism
- LLM tá»± kiá»ƒm tra cÃ¢u tráº£ lá»i trÆ°á»›c khi tráº£ vá»
- PhÃ¡t hiá»‡n hallucination vÃ  thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c
- Chá»‰ Ã¡p dá»¥ng cho "Deep mode" Ä‘á»ƒ tiáº¿t kiá»‡m cost
- Validation vá»›i confidence score vÃ  auto-correction

#### 5. Abstain When Uncertain
- HÆ°á»›ng dáº«n LLM tá»« chá»‘i tráº£ lá»i khi khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin
- TrÃ¡nh bá»‹a Ä‘áº·t thÃ´ng tin (hallucination)
- Response máº«u: "Em Æ¡i, pháº§n nÃ y cÃ´ chÆ°a cÃ³ Ä‘á»§ thÃ´ng tin..."

#### 6. RAG vá»›i TrÃ­ch Dáº«n Nguá»“n
- Retriever tráº£ vá» metadata (source, lesson_id)
- Format context kÃ¨m nguá»“n: `[Nguá»“n 1: bai_2_phan_so.txt]`
- LLM Ä‘Æ°á»£c yÃªu cáº§u dá»±a vÃ o nguá»“n cá»¥ thá»ƒ
- TÄƒng tÃ­nh minh báº¡ch vÃ  truy váº¿t Ä‘Æ°á»£c thÃ´ng tin

### So sÃ¡nh vá»›i Gemini

Google Gemini cÃ³ "Grounding with Google Search" giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c:
- TÃ¬m kiáº¿m web real-time
- TrÃ­ch dáº«n nguá»“n tin cáº­y
- Äiá»ƒm accuracy: 8.5/10 (vs ChatGPT 8.3/10)

Há»‡ thá»‘ng nÃ y báº¯t chÆ°á»›c cÃ¡ch tiáº¿p cáº­n Ä‘Ã³ báº±ng:
- RAG vá»›i ChromaDB (thay vÃ¬ Google Search)
- Metadata tracking vÃ  citation
- Validation layer Ä‘á»ƒ tá»± kiá»ƒm tra
